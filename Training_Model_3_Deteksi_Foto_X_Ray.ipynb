{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKV1eExjrr+uIbhpYD5jyg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elangbijak4/Riset-AI-Medis/blob/main/Training_Model_3_Deteksi_Foto_X_Ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4zRWeuLcC02U"
      },
      "outputs": [],
      "source": [
        "# Install dan autentikasi\n",
        "!pip install -q kaggle pydicom tqdm imgaug\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unggah kaggle.json dari Google Drive ke folder ~/.kaggle\n",
        "import os, io\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "file_id = drive_service.files().list(q=\"name='kaggle.json'\", fields=\"files(id)\").execute()['files'][0]['id']\n",
        "fh = io.FileIO('/root/.kaggle/kaggle.json', 'wb')\n",
        "drive_service.files().get_media(fileId=file_id).download(fh)\n",
        "os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "# Download RSNA dataset (Stage 1)\n",
        "!kaggle competitions download -c rsna-pneumonia-detection-challenge\n",
        "!unzip -q stage_1_train_images.zip\n",
        "!unzip -q stage_1_train_labels.csv.zip\n",
        "\n",
        "# Alternatif: chestX-ray14 via Activeloop Deep Lake (jika tersedia)\n",
        "!pip install -q deeplake\n",
        "import deeplake\n",
        "ds = deeplake.load('hub://activeloop/nih-chest-xray-train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, glob, pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# Load label CSV\n",
        "df = pd.read_csv('stage_1_train_labels.csv')\n",
        "# Contoh filter untuk pneumonia positif only\n",
        "df_pos = df[df['Target'] == 1]\n",
        "\n",
        "# Load dan augment gambar\n",
        "def load_and_augment(fp):\n",
        "    d = pydicom.dcmread(fp).pixel_array\n",
        "    d = cv2.resize(d, (512,512))\n",
        "    seq = iaa.Sequential([iaa.GaussianBlur((0,3.0))])\n",
        "    return seq(image=d)\n",
        "\n",
        "# Contoh pemrosesan per-batch\n",
        "for idx, row in df_pos.sample(4).iterrows():\n",
        "    img = load_and_augment(f\"stage_1_train_images/{row['patientId']}.dcm\")\n",
        "    x1, y1, w, h = row[['x','y','width','height']]\n",
        "    cv2.rectangle(img, (int(x1), int(y1)), (int(x1+w), int(y1+h)), (255,0,0), 2)\n",
        "    plt.imshow(img, cmap='gray'); plt.show()"
      ],
      "metadata": {
        "id": "ncVtLAvcDNI-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Gunakan ImageDataGenerator untuk ChestX-ray14 ini\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_gen = datagen.flow_from_directory('/content/drive/MyDrive/datasets/ChestXray14',\n",
        "                                         target_size=(224,224), class_mode='binary', subset='training')\n",
        "val_gen   = datagen.flow_from_directory(..., subset='validation')\n",
        "\n",
        "# Bangun model transfer learning\n",
        "def build_model(base):\n",
        "    base.trainable = False\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    m = Model(base.input, out)\n",
        "    m.compile('adam', 'binary_crossentropy', ['accuracy'])\n",
        "    return m\n",
        "\n",
        "base = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "model = build_model(base)\n",
        "\n",
        "# Fine-tune\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=5)"
      ],
      "metadata": {
        "id": "CY9e7IooDZH2"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}